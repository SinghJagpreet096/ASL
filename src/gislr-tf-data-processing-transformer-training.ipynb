{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## to be run on virtual machine such as kaggle or google colab. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:49:56.126024Z","iopub.status.busy":"2023-04-04T19:49:56.125207Z","iopub.status.idle":"2023-04-04T19:50:04.966672Z","shell.execute_reply":"2023-04-04T19:50:04.964623Z","shell.execute_reply.started":"2023-04-04T19:49:56.125984Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import seaborn as sn\n","\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import train_test_split, GroupShuffleSplit \n","\n","import glob\n","import sys\n","import os\n","import math\n","import gc\n","import sys\n","import sklearn\n","import scipy\n","\n","print(f'Tensorflow V{tf.__version__}')\n","print(f'Keras V{tf.keras.__version__}')\n","print(f'Python V{sys.version}')"]},{"cell_type":"markdown","metadata":{},"source":["# Plot Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:04.970594Z","iopub.status.busy":"2023-04-04T19:50:04.969947Z","iopub.status.idle":"2023-04-04T19:50:04.979901Z","shell.execute_reply":"2023-04-04T19:50:04.976462Z","shell.execute_reply.started":"2023-04-04T19:50:04.970563Z"},"trusted":true},"outputs":[],"source":["# MatplotLib Global Settings\n","mpl.rcParams.update(mpl.rcParamsDefault)\n","mpl.rcParams['xtick.labelsize'] = 16\n","mpl.rcParams['ytick.labelsize'] = 16\n","mpl.rcParams['axes.labelsize'] = 18\n","mpl.rcParams['axes.titlesize'] = 24"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:04.982216Z","iopub.status.busy":"2023-04-04T19:50:04.981614Z","iopub.status.idle":"2023-04-04T19:50:04.994563Z","shell.execute_reply":"2023-04-04T19:50:04.993529Z","shell.execute_reply.started":"2023-04-04T19:50:04.982175Z"},"trusted":true},"outputs":[],"source":["# If True, processing data from scratch\n","# If False, loads preprocessed data\n","PREPROCESS_DATA = False\n","TRAIN_MODEL = True\n","# True: use 10% of participants as validation set\n","# False: use all data for training -> gives better LB result\n","USE_VAL = False\n","\n","N_ROWS = 543\n","N_DIMS = 3\n","DIM_NAMES = ['x', 'y', 'z']\n","SEED = 42\n","NUM_CLASSES = 250\n","IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n","VERBOSE = 1 if IS_INTERACTIVE else 2\n","\n","INPUT_SIZE = 64\n","\n","BATCH_ALL_SIGNS_N = 4\n","BATCH_SIZE = 256\n","N_EPOCHS = 100\n","LR_MAX = 1e-3\n","N_WARMUP_EPOCHS = 0\n","WD_RATIO = 0.05\n","MASK_VAL = 4237"]},{"cell_type":"markdown","metadata":{},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:04.998147Z","iopub.status.busy":"2023-04-04T19:50:04.997672Z","iopub.status.idle":"2023-04-04T19:50:05.005923Z","shell.execute_reply":"2023-04-04T19:50:05.004788Z","shell.execute_reply.started":"2023-04-04T19:50:04.998094Z"},"trusted":true},"outputs":[],"source":["# Prints Shape and Dtype For List Of Variables\n","def print_shape_dtype(l, names):\n","    for e, n in zip(l, names):\n","        print(f'{n} shape: {e.shape}, dtype: {e.dtype}')"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:05.008208Z","iopub.status.busy":"2023-04-04T19:50:05.007801Z","iopub.status.idle":"2023-04-04T19:50:05.220155Z","shell.execute_reply":"2023-04-04T19:50:05.219155Z","shell.execute_reply.started":"2023-04-04T19:50:05.008167Z"},"trusted":true},"outputs":[],"source":["# Read Training Data\n","if IS_INTERACTIVE or not PREPROCESS_DATA:\n","    train = pd.read_csv('/kaggle/input/asl-signs/train.csv').sample(int(5e3), random_state=SEED)\n","else:\n","    train = pd.read_csv('/kaggle/input/asl-signs/train.csv')\n","\n","N_SAMPLES = len(train)\n","print(f'N_SAMPLES: {N_SAMPLES}')"]},{"cell_type":"markdown","metadata":{},"source":["# Add File Path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:05.223881Z","iopub.status.busy":"2023-04-04T19:50:05.223579Z","iopub.status.idle":"2023-04-04T19:50:05.237629Z","shell.execute_reply":"2023-04-04T19:50:05.236505Z","shell.execute_reply.started":"2023-04-04T19:50:05.223852Z"},"trusted":true},"outputs":[],"source":["# Get complete file path to file\n","def get_file_path(path):\n","    return f'/kaggle/input/asl-signs/{path}'\n","\n","train['file_path'] = train['path'].apply(get_file_path)"]},{"cell_type":"markdown","metadata":{},"source":["# Ordinally Encode Sign"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:05.239905Z","iopub.status.busy":"2023-04-04T19:50:05.23953Z","iopub.status.idle":"2023-04-04T19:50:05.261882Z","shell.execute_reply":"2023-04-04T19:50:05.260992Z","shell.execute_reply.started":"2023-04-04T19:50:05.239864Z"},"trusted":true},"outputs":[],"source":["# Add ordinally Encoded Sign (assign number to each sign name)\n","train['sign_ord'] = train['sign'].astype('category').cat.codes\n","\n","# Dictionaries to translate sign <-> ordinal encoded sign\n","SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n","ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:05.263716Z","iopub.status.busy":"2023-04-04T19:50:05.263444Z","iopub.status.idle":"2023-04-04T19:50:05.3004Z","shell.execute_reply":"2023-04-04T19:50:05.299105Z","shell.execute_reply.started":"2023-04-04T19:50:05.26369Z"},"trusted":true},"outputs":[],"source":["display(train.head(30))\n","display(train.info())"]},{"cell_type":"markdown","metadata":{},"source":["# Video Statistics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:05.30287Z","iopub.status.busy":"2023-04-04T19:50:05.301701Z","iopub.status.idle":"2023-04-04T19:50:28.249854Z","shell.execute_reply":"2023-04-04T19:50:28.248675Z","shell.execute_reply.started":"2023-04-04T19:50:05.30282Z"},"trusted":true},"outputs":[],"source":["N = int(1e3) if (IS_INTERACTIVE or not PREPROCESS_DATA) else int(10e3)\n","N_UNIQUE_FRAMES = np.zeros(N, dtype=np.uint16)\n","N_MISSING_FRAMES = np.zeros(N, dtype=np.uint16)\n","MAX_FRAME = np.zeros(N, dtype=np.uint16)\n","\n","PERCENTILES = [0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99, 0.999]\n","\n","for idx, file_path in enumerate(tqdm(train['file_path'].sample(N, random_state=SEED))):\n","    df = pd.read_parquet(file_path)\n","    N_UNIQUE_FRAMES[idx] = df['frame'].nunique()\n","    N_MISSING_FRAMES[idx] = (df['frame'].max() - df['frame'].min()) - df['frame'].nunique() + 1\n","    MAX_FRAME[idx] = df['frame'].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:28.254718Z","iopub.status.busy":"2023-04-04T19:50:28.254387Z","iopub.status.idle":"2023-04-04T19:50:28.772325Z","shell.execute_reply":"2023-04-04T19:50:28.771245Z","shell.execute_reply.started":"2023-04-04T19:50:28.254687Z"},"trusted":true},"outputs":[],"source":["# Number of unique frames in each video\n","display(pd.Series(N_UNIQUE_FRAMES).describe(percentiles=PERCENTILES).to_frame('N_UNIQUE_FRAMES'))\n","\n","plt.figure(figsize=(15,8))\n","plt.title('Number of Unique Frames', size=24)\n","pd.Series(N_UNIQUE_FRAMES).plot(kind='hist', bins=128)\n","plt.grid()\n","xlim = math.ceil(plt.xlim()[1])\n","plt.xlim(0, xlim)\n","plt.xticks(np.arange(0, xlim+25, 25))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:28.775565Z","iopub.status.busy":"2023-04-04T19:50:28.773753Z","iopub.status.idle":"2023-04-04T19:50:29.243774Z","shell.execute_reply":"2023-04-04T19:50:29.242845Z","shell.execute_reply.started":"2023-04-04T19:50:28.775511Z"},"trusted":true},"outputs":[],"source":["# Number of missing frames, consecutive frames with missing intermediate frame, i.e. 1,2,4,5 -> 3 is missing\n","display(pd.Series(N_MISSING_FRAMES).describe(percentiles=PERCENTILES).to_frame('N_MISSING_FRAMES'))\n","\n","plt.figure(figsize=(15,8))\n","plt.title('Number of Missing Frames', size=24)\n","pd.Series(N_MISSING_FRAMES).plot(kind='hist', bins=128)\n","plt.grid()\n","plt.xlim(0, math.ceil(plt.xlim()[1]))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:29.246218Z","iopub.status.busy":"2023-04-04T19:50:29.245258Z","iopub.status.idle":"2023-04-04T19:50:29.700493Z","shell.execute_reply":"2023-04-04T19:50:29.699256Z","shell.execute_reply.started":"2023-04-04T19:50:29.246175Z"},"trusted":true},"outputs":[],"source":["# Maximum frame number\n","display(pd.Series(MAX_FRAME).describe(percentiles=PERCENTILES).to_frame('MAX_FRAME'))\n","\n","plt.figure(figsize=(15,8))\n","plt.title('Maximum Frames Index', size=24)\n","pd.Series(MAX_FRAME).plot(kind='hist', bins=128)\n","plt.grid()\n","plt.xlim(0, math.ceil(plt.xlim()[1]))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Landmark Indices"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:29.704517Z","iopub.status.busy":"2023-04-04T19:50:29.704142Z","iopub.status.idle":"2023-04-04T19:50:29.718911Z","shell.execute_reply":"2023-04-04T19:50:29.717601Z","shell.execute_reply.started":"2023-04-04T19:50:29.704483Z"},"trusted":true},"outputs":[],"source":["USE_TYPES = ['left_hand', 'pose', 'right_hand']\n","START_IDX = 468\n","LIPS_IDXS0 = np.array([\n","        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n","        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n","        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n","        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n","    ])\n","# Landmark indices in original data\n","LEFT_HAND_IDXS0 = np.arange(468,489)\n","RIGHT_HAND_IDXS0 = np.arange(522,543)\n","LEFT_POSE_IDXS0 = np.array([502, 504, 506, 508, 510])\n","RIGHT_POSE_IDXS0 = np.array([503, 505, 507, 509, 511])\n","LANDMARK_IDXS_LEFT_DOMINANT0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, LEFT_POSE_IDXS0))\n","LANDMARK_IDXS_RIGHT_DOMINANT0 = np.concatenate((LIPS_IDXS0, RIGHT_HAND_IDXS0, RIGHT_POSE_IDXS0))\n","HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n","N_COLS = LANDMARK_IDXS_LEFT_DOMINANT0.size\n","# Landmark indices in processed data\n","LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LIPS_IDXS0)).squeeze()\n","LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_HAND_IDXS0)).squeeze()\n","RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, RIGHT_HAND_IDXS0)).squeeze()\n","HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, HAND_IDXS0)).squeeze()\n","POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_POSE_IDXS0)).squeeze()\n","\n","print(f'# HAND_IDXS: {len(HAND_IDXS)}, N_COLS: {N_COLS}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:29.721761Z","iopub.status.busy":"2023-04-04T19:50:29.720519Z","iopub.status.idle":"2023-04-04T19:50:29.729779Z","shell.execute_reply":"2023-04-04T19:50:29.728308Z","shell.execute_reply.started":"2023-04-04T19:50:29.721714Z"},"trusted":true},"outputs":[],"source":["LIPS_START = 0\n","LEFT_HAND_START = LIPS_IDXS.size\n","RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n","POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n","\n","print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"]},{"cell_type":"markdown","metadata":{},"source":["# Process Data Tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:29.732859Z","iopub.status.busy":"2023-04-04T19:50:29.731699Z","iopub.status.idle":"2023-04-04T19:50:29.740542Z","shell.execute_reply":"2023-04-04T19:50:29.739201Z","shell.execute_reply.started":"2023-04-04T19:50:29.732817Z"},"trusted":true},"outputs":[],"source":["# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n","ROWS_PER_FRAME = 543  # number of landmarks per frame\n","\n","def load_relevant_data_subset(pq_path):\n","    data_columns = ['x', 'y', 'z']\n","    data = pd.read_parquet(pq_path, columns=data_columns)\n","    n_frames = int(len(data) / ROWS_PER_FRAME)\n","    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n","    return data.astype(np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:29.743093Z","iopub.status.busy":"2023-04-04T19:50:29.742291Z","iopub.status.idle":"2023-04-04T19:50:32.446095Z","shell.execute_reply":"2023-04-04T19:50:32.444934Z","shell.execute_reply.started":"2023-04-04T19:50:29.743051Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","    Tensorflow layer to process data in TFLite\n","    Data needs to be processed in the model itself, so we can not use Python\n","\"\"\" \n","class PreprocessLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(PreprocessLayer, self).__init__()\n","        normalisation_correction = tf.constant([\n","                    # Add 0.50 to left hand (original right hand) and substract 0.50 of right hand (original left hand)\n","                    [0] * len(LIPS_IDXS) + [0.50] * len(LEFT_HAND_IDXS) + [0.50] * len(POSE_IDXS),\n","                    # Y coordinates stay intact\n","                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n","                    # Z coordinates stay intact\n","                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n","                ],\n","                dtype=tf.float32,\n","            )\n","        self.normalisation_correction = tf.transpose(normalisation_correction, [1,0])\n","        \n","    def pad_edge(self, t, repeats, side):\n","        if side == 'LEFT':\n","            return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n","        elif side == 'RIGHT':\n","            return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n","    \n","    @tf.function(\n","        input_signature=(tf.TensorSpec(shape=[None,N_ROWS,N_DIMS], dtype=tf.float32),),\n","    )\n","    def call(self, data0):\n","        # Number of Frames in Video\n","        N_FRAMES0 = tf.shape(data0)[0]\n","        \n","        # Find dominant hand by comparing summed absolute coordinates\n","        left_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1))\n","        right_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1))\n","        left_dominant = left_hand_sum >= right_hand_sum\n","        \n","        # Count non NaN Hand values in each frame for the dominant hand\n","        if left_dominant:\n","            frames_hands_non_nan_sum = tf.math.reduce_sum(\n","                    tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1),\n","                    axis=[1, 2],\n","                )\n","        else:\n","            frames_hands_non_nan_sum = tf.math.reduce_sum(\n","                    tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1),\n","                    axis=[1, 2],\n","                )\n","        \n","        # Find frames indices with coordinates of dominant hand\n","        non_empty_frames_idxs = tf.where(frames_hands_non_nan_sum > 0)\n","        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n","        # Filter frames\n","        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n","        \n","        # Cast Indices in float32 to be compatible with Tensorflow Lite\n","        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n","        # Normalize to start with 0\n","        non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n","        \n","        # Number of Frames in Filtered Video\n","        N_FRAMES = tf.shape(data)[0]\n","        \n","        # Gather Relevant Landmark Columns\n","        if left_dominant:\n","            data = tf.gather(data, LANDMARK_IDXS_LEFT_DOMINANT0, axis=1)\n","        else:\n","            data = tf.gather(data, LANDMARK_IDXS_RIGHT_DOMINANT0, axis=1)\n","            data = (\n","                    self.normalisation_correction + (\n","                        (data - self.normalisation_correction) * tf.where(self.normalisation_correction != 0, -1.0, 1.0))\n","                )\n","        \n","        # Video fits in INPUT_SIZE\n","        if N_FRAMES < INPUT_SIZE:\n","            # Pad With -1 to indicate padding\n","            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, INPUT_SIZE-N_FRAMES]], constant_values=-1)\n","            # Pad Data With Zeros\n","            data = tf.pad(data, [[0, INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n","            # Fill NaN Values With 0\n","            data = tf.where(tf.math.is_nan(data), 0.0, data)\n","            return data, non_empty_frames_idxs\n","        # Video needs to be downsampled to INPUT_SIZE\n","        else:\n","            # Repeat\n","            if N_FRAMES < INPUT_SIZE**2:\n","                repeats = tf.math.floordiv(INPUT_SIZE * INPUT_SIZE, N_FRAMES0)\n","                data = tf.repeat(data, repeats=repeats, axis=0)\n","                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n","\n","            # Pad To Multiple Of Input Size\n","            pool_size = tf.math.floordiv(len(data), INPUT_SIZE)\n","            if tf.math.mod(len(data), INPUT_SIZE) > 0:\n","                pool_size += 1\n","\n","            if pool_size == 1:\n","                pad_size = (pool_size * INPUT_SIZE) - len(data)\n","            else:\n","                pad_size = (pool_size * INPUT_SIZE) % len(data)\n","\n","            # Pad Start/End with Start/End value\n","            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n","            pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n","            if tf.math.mod(pad_size, 2) > 0:\n","                pad_right += 1\n","\n","            # Pad By Concatenating Left/Right Edge Values\n","            data = self.pad_edge(data, pad_left, 'LEFT')\n","            data = self.pad_edge(data, pad_right, 'RIGHT')\n","\n","            # Pad Non Empty Frame Indices\n","            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n","            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n","\n","            # Reshape to Mean Pool\n","            data = tf.reshape(data, [INPUT_SIZE, -1, N_COLS, N_DIMS])\n","            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [INPUT_SIZE, -1])\n","\n","            # Mean Pool\n","            data = tf.experimental.numpy.nanmean(data, axis=1)\n","            non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n","\n","            # Fill NaN Values With 0\n","            data = tf.where(tf.math.is_nan(data), 0.0, data)\n","            \n","            return data, non_empty_frames_idxs\n","    \n","preprocess_layer = PreprocessLayer()"]},{"cell_type":"markdown","metadata":{},"source":["# Interpolate NaN Values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:32.448149Z","iopub.status.busy":"2023-04-04T19:50:32.447775Z","iopub.status.idle":"2023-04-04T19:50:32.453632Z","shell.execute_reply":"2023-04-04T19:50:32.45263Z","shell.execute_reply.started":"2023-04-04T19:50:32.448111Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","    face: 0:468\n","    left_hand: 468:489\n","    pose: 489:522\n","    right_hand: 522:544\n","        \n","\"\"\"\n","def get_data(file_path):\n","    # Load Raw Data\n","    data = load_relevant_data_subset(file_path)\n","    # Process Data Using Tensorflow\n","    data = preprocess_layer(data)\n","    \n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["# Create Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:32.456539Z","iopub.status.busy":"2023-04-04T19:50:32.455742Z","iopub.status.idle":"2023-04-04T19:50:32.470052Z","shell.execute_reply":"2023-04-04T19:50:32.469048Z","shell.execute_reply.started":"2023-04-04T19:50:32.456502Z"},"trusted":true},"outputs":[],"source":["# Get the full dataset\n","def preprocess_data():\n","    # Create arrays to save data\n","    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n","    y = np.zeros([N_SAMPLES], dtype=np.int32)\n","    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n","\n","    # Fill X/y\n","    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n","        # Log message every 5000 samples\n","        if row_idx % 5000 == 0:\n","            print(f'Generated {row_idx}/{N_SAMPLES}')\n","\n","        data, non_empty_frame_idxs = get_data(file_path)\n","        X[row_idx] = data\n","        y[row_idx] = sign_ord\n","        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n","        # Sanity check, data should not contain NaN values\n","        if np.isnan(data).sum() > 0:\n","            print(row_idx)\n","            return data\n","\n","    # Save X/y\n","    np.save('X.npy', X)\n","    np.save('y.npy', y)\n","    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n","    \n","    # Save Validation\n","    splitter = GroupShuffleSplit(test_size=0.10, n_splits=2, random_state=SEED)\n","    PARTICIPANT_IDS = train['participant_id'].values\n","    train_idxs, val_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n","\n","    # Save Train\n","    X_train = X[train_idxs]\n","    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n","    y_train = y[train_idxs]\n","    np.save('X_train.npy', X_train)\n","    np.save('y_train.npy', y_train)\n","    np.save('NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n","    # Save Validation\n","    X_val = X[val_idxs]\n","    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n","    y_val = y[val_idxs]\n","    np.save('X_val.npy', X_val)\n","    np.save('y_val.npy', y_val)\n","    np.save('NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n","    # Split Statistics\n","    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n","    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n","    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:32.472885Z","iopub.status.busy":"2023-04-04T19:50:32.471886Z","iopub.status.idle":"2023-04-04T19:50:59.908161Z","shell.execute_reply":"2023-04-04T19:50:59.906159Z","shell.execute_reply.started":"2023-04-04T19:50:32.472855Z"},"trusted":true},"outputs":[],"source":["# Preprocess All Data From Scratch\n","if PREPROCESS_DATA:\n","    preprocess_data()\n","    ROOT_DIR = '.'\n","else:\n","    ROOT_DIR = '/kaggle/input/gislr-dataset-public'\n","    \n","# Load Data\n","if USE_VAL:\n","    # Load Train\n","    X_train = np.load(f'{ROOT_DIR}/X_train.npy')\n","    y_train = np.load(f'{ROOT_DIR}/y_train.npy')\n","    NON_EMPTY_FRAME_IDXS_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_TRAIN.npy')\n","    # Load Val\n","    X_val = np.load(f'{ROOT_DIR}/X_val.npy')\n","    y_val = np.load(f'{ROOT_DIR}/y_val.npy')\n","    NON_EMPTY_FRAME_IDXS_VAL = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS_VAL.npy')\n","    # Define validation Data\n","    validation_data = ({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, y_val)\n","else:\n","    X_train = np.load(f'{ROOT_DIR}/X.npy')\n","    y_train = np.load(f'{ROOT_DIR}/y.npy')\n","    NON_EMPTY_FRAME_IDXS_TRAIN = np.load(f'{ROOT_DIR}/NON_EMPTY_FRAME_IDXS.npy')\n","    validation_data = None\n","\n","# Train \n","print_shape_dtype([X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN], ['X_train', 'y_train', 'NON_EMPTY_FRAME_IDXS_TRAIN'])\n","# Val\n","if USE_VAL:\n","    print_shape_dtype([X_val, y_val, NON_EMPTY_FRAME_IDXS_VAL], ['X_val', 'y_val', 'NON_EMPTY_FRAME_IDXS_VAL'])\n","# Sanity Check\n","print(f'# NaN Values X_train: {np.isnan(X_train).sum()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:59.911088Z","iopub.status.busy":"2023-04-04T19:50:59.910339Z","iopub.status.idle":"2023-04-04T19:50:59.925879Z","shell.execute_reply":"2023-04-04T19:50:59.924122Z","shell.execute_reply.started":"2023-04-04T19:50:59.911048Z"},"trusted":true},"outputs":[],"source":["# Class Count\n","display(pd.Series(y_train).value_counts().to_frame('Class Count').iloc[[0,1,2,3,4, -5,-4,-3,-2,-1]])"]},{"cell_type":"markdown","metadata":{},"source":["# Number Of Frames"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:50:59.9293Z","iopub.status.busy":"2023-04-04T19:50:59.927731Z","iopub.status.idle":"2023-04-04T19:51:12.191206Z","shell.execute_reply":"2023-04-04T19:51:12.190289Z","shell.execute_reply.started":"2023-04-04T19:50:59.929272Z"},"trusted":true},"outputs":[],"source":["# Vast majority of samples fits has less than 32 non empty frames\n","N_EMPTY_FRAMES = (NON_EMPTY_FRAME_IDXS_TRAIN != -1).sum(axis=1) \n","N_EMPTY_FRAMES_WATERFALL = []\n","for n in tqdm(range(1,INPUT_SIZE+1)):\n","    N_EMPTY_FRAMES_WATERFALL.append(sum(N_EMPTY_FRAMES >= n) / len(NON_EMPTY_FRAME_IDXS_TRAIN) * 100)\n","\n","plt.figure(figsize=(18,10))\n","plt.title('Waterfall Plot For Number Of Non Empty Frames')\n","pd.Series(N_EMPTY_FRAMES_WATERFALL).plot(kind='bar')\n","plt.grid(axis='y')\n","plt.xticks(np.arange(INPUT_SIZE), np.arange(1, INPUT_SIZE+1))\n","plt.xlabel('Number of Non Empty Frames', size=16)\n","plt.yticks(np.arange(0, 100+10, 10))\n","plt.ylim(0, 100)\n","plt.ylabel('Percentage of Samples With At Least N Non Empty Frames', size=16)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Percentage of Frames Filled"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:51:12.192541Z","iopub.status.busy":"2023-04-04T19:51:12.19228Z","iopub.status.idle":"2023-04-04T19:51:12.207935Z","shell.execute_reply":"2023-04-04T19:51:12.206642Z","shell.execute_reply.started":"2023-04-04T19:51:12.192516Z"},"trusted":true},"outputs":[],"source":["# Percentage of frames filled, this is the maximum fill percentage of each landmark\n","P_DATA_FILLED = (NON_EMPTY_FRAME_IDXS_TRAIN != -1).sum() / NON_EMPTY_FRAME_IDXS_TRAIN.size * 100\n","print(f'P_DATA_FILLED: {P_DATA_FILLED:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Statistics - Lips"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:51:12.211059Z","iopub.status.busy":"2023-04-04T19:51:12.209759Z","iopub.status.idle":"2023-04-04T19:51:27.165956Z","shell.execute_reply":"2023-04-04T19:51:27.164628Z","shell.execute_reply.started":"2023-04-04T19:51:12.211029Z"},"trusted":true},"outputs":[],"source":["# Percentage of Lips Measurements\n","P_LEFT_LIPS_MEASUREMENTS = (X_train[:,:,LIPS_IDXS] != 0).sum() / X_train[:,:,LIPS_IDXS].size / P_DATA_FILLED * 1e4\n","print(f'P_LEFT_LIPS_MEASUREMENTS: {P_LEFT_LIPS_MEASUREMENTS:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:51:27.168219Z","iopub.status.busy":"2023-04-04T19:51:27.167584Z","iopub.status.idle":"2023-04-04T19:51:45.328354Z","shell.execute_reply":"2023-04-04T19:51:45.3272Z","shell.execute_reply.started":"2023-04-04T19:51:27.168176Z"},"trusted":true},"outputs":[],"source":["def get_lips_mean_std():\n","    # LIPS\n","    LIPS_MEAN_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n","    LIPS_MEAN_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n","    LIPS_STD_X = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n","    LIPS_STD_Y = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n","\n","    fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n","\n","    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, N_DIMS, -1]) )):\n","        for dim, l in enumerate(ll):\n","            v = l[np.nonzero(l)]\n","            if dim == 0: # X\n","                LIPS_MEAN_X[col] = v.mean()\n","                LIPS_STD_X[col] = v.std()\n","            if dim == 1: # Y\n","                LIPS_MEAN_Y[col] = v.mean()\n","                LIPS_STD_Y[col] = v.std()\n","\n","            axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n","\n","    for ax, dim_name in zip(axes, DIM_NAMES):\n","        ax.set_title(f'Lips {dim_name.upper()} Dimension', size=24)\n","        ax.tick_params(axis='x', labelsize=8)\n","        ax.grid(axis='y')\n","\n","    plt.subplots_adjust(hspace=0.50)\n","    plt.show()\n","\n","    LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n","    LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T\n","    \n","    return LIPS_MEAN, LIPS_STD\n","\n","LIPS_MEAN, LIPS_STD = get_lips_mean_std()"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Statistics - Hands"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:51:45.332667Z","iopub.status.busy":"2023-04-04T19:51:45.329903Z","iopub.status.idle":"2023-04-04T19:51:53.589007Z","shell.execute_reply":"2023-04-04T19:51:53.58767Z","shell.execute_reply.started":"2023-04-04T19:51:45.332621Z"},"trusted":true},"outputs":[],"source":["# Verify Normalised to Left Hand Dominant\n","P_LEFT_HAND_MEASUREMENTS = (X_train[:,:,LEFT_HAND_IDXS] != 0).sum() / X_train[:,:,LEFT_HAND_IDXS].size / P_DATA_FILLED * 1e4\n","# P_RIGHT_HAND_MEASUREMENTS = (X_train[:,:,RIGHT_HAND_IDXS] != 0).sum() / X_train[:,:,RIGHT_HAND_IDXS].size / P_DATA_FILLED * 1e4\n","print(f'P_LEFT_HAND_MEASUREMENTS: {P_LEFT_HAND_MEASUREMENTS:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:51:53.591355Z","iopub.status.busy":"2023-04-04T19:51:53.590675Z","iopub.status.idle":"2023-04-04T19:52:03.425162Z","shell.execute_reply":"2023-04-04T19:52:03.424123Z","shell.execute_reply.started":"2023-04-04T19:51:53.591316Z"},"trusted":true},"outputs":[],"source":["def get_left_right_hand_mean_std():\n","    # LEFT HAND\n","    LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n","    LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n","    LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n","    LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n","\n","    fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n","\n","    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,LEFT_HAND_IDXS], [2,3,0,1]).reshape([LEFT_HAND_IDXS.size, N_DIMS, -1]) )):\n","        for dim, l in enumerate(ll):\n","            v = l[np.nonzero(l)]\n","            if dim == 0: # X\n","                LEFT_HANDS_MEAN_X[col] = v.mean()\n","                LEFT_HANDS_STD_X[col] = v.std()\n","            if dim == 1: # Y\n","                LEFT_HANDS_MEAN_Y[col] = v.mean()\n","                LEFT_HANDS_STD_Y[col] = v.std()\n","            # Plot\n","            axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n","\n","    for ax, dim_name in zip(axes, DIM_NAMES):\n","        ax.set_title(f'Hands {dim_name.upper()} Dimension', size=24)\n","        ax.tick_params(axis='x', labelsize=8)\n","        ax.grid(axis='y')\n","\n","    plt.subplots_adjust(hspace=0.50)\n","    plt.show()\n","\n","    LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n","    LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n","    \n","    return LEFT_HANDS_MEAN, LEFT_HANDS_STD\n","\n","LEFT_HANDS_MEAN, LEFT_HANDS_STD = get_left_right_hand_mean_std()"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Statistics - Pose"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:03.427582Z","iopub.status.busy":"2023-04-04T19:52:03.42693Z","iopub.status.idle":"2023-04-04T19:52:05.449412Z","shell.execute_reply":"2023-04-04T19:52:05.447941Z","shell.execute_reply.started":"2023-04-04T19:52:03.427545Z"},"trusted":true},"outputs":[],"source":["# Percentage of Lips Measurements\n","P_POSE_MEASUREMENTS = (X_train[:,:,POSE_IDXS] != 0).sum() / X_train[:,:,POSE_IDXS].size / P_DATA_FILLED * 1e4\n","print(f'P_POSE_MEASUREMENTS: {P_POSE_MEASUREMENTS:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:05.457231Z","iopub.status.busy":"2023-04-04T19:52:05.456938Z","iopub.status.idle":"2023-04-04T19:52:08.298084Z","shell.execute_reply":"2023-04-04T19:52:08.296908Z","shell.execute_reply.started":"2023-04-04T19:52:05.457203Z"},"trusted":true},"outputs":[],"source":["def get_pose_mean_std():\n","    # POSE\n","    POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n","    POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n","    POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n","    POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n","\n","    fig, axes = plt.subplots(3, 1, figsize=(15, N_DIMS*6))\n","\n","    for col, ll in enumerate(tqdm( np.transpose(X_train[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, N_DIMS, -1]) )):\n","        for dim, l in enumerate(ll):\n","            v = l[np.nonzero(l)]\n","            if dim == 0: # X\n","                POSE_MEAN_X[col] = v.mean()\n","                POSE_STD_X[col] = v.std()\n","            if dim == 1: # Y\n","                POSE_MEAN_Y[col] = v.mean()\n","                POSE_STD_Y[col] = v.std()\n","\n","            axes[dim].boxplot(v, notch=False, showfliers=False, positions=[col], whis=[5,95])\n","\n","    for ax, dim_name in zip(axes, DIM_NAMES):\n","        ax.set_title(f'Pose {dim_name.upper()} Dimension', size=24)\n","        ax.tick_params(axis='x', labelsize=8)\n","        ax.grid(axis='y')\n","\n","    plt.subplots_adjust(hspace=0.50)\n","    plt.show()\n","\n","    POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n","    POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T\n","    \n","    return POSE_MEAN, POSE_STD\n","\n","POSE_MEAN, POSE_STD = get_pose_mean_std()"]},{"cell_type":"markdown","metadata":{},"source":["# Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.300251Z","iopub.status.busy":"2023-04-04T19:52:08.299797Z","iopub.status.idle":"2023-04-04T19:52:08.312412Z","shell.execute_reply":"2023-04-04T19:52:08.311296Z","shell.execute_reply.started":"2023-04-04T19:52:08.300201Z"},"trusted":true},"outputs":[],"source":["# Custom sampler to get a batch containing N times all signs\n","def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=BATCH_ALL_SIGNS_N):\n","    # Arrays to store batch in\n","    X_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n","    y_batch = np.arange(0, NUM_CLASSES, step=1/n, dtype=np.float32).astype(np.int64)\n","    non_empty_frame_idxs_batch = np.zeros([NUM_CLASSES*n, INPUT_SIZE], dtype=np.float32)\n","    \n","    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n","    CLASS2IDXS = {}\n","    for i in range(NUM_CLASSES):\n","        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n","            \n","    while True:\n","        # Fill batch arrays\n","        for i in range(NUM_CLASSES):\n","            idxs = np.random.choice(CLASS2IDXS[i], n)\n","            X_batch[i*n:(i+1)*n] = X[idxs]\n","            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n","        \n","        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.314718Z","iopub.status.busy":"2023-04-04T19:52:08.314248Z","iopub.status.idle":"2023-04-04T19:52:08.395873Z","shell.execute_reply":"2023-04-04T19:52:08.394805Z","shell.execute_reply.started":"2023-04-04T19:52:08.314663Z"},"trusted":true},"outputs":[],"source":["dummy_dataset = get_train_batch_all_signs(X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN)\n","X_batch, y_batch = next(dummy_dataset)\n","\n","for k, v in X_batch.items():\n","    print(f'{k} shape: {v.shape}, dtype: {v.dtype}')\n","\n","# Batch shape/dtype\n","print(f'y_batch shape: {y_batch.shape}, dtype: {y_batch.dtype}')\n","# Verify each batch contains each sign exactly N times\n","display(pd.Series(y_batch).value_counts().to_frame('Counts'))"]},{"cell_type":"markdown","metadata":{},"source":["# Model Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.398332Z","iopub.status.busy":"2023-04-04T19:52:08.397231Z","iopub.status.idle":"2023-04-04T19:52:08.406717Z","shell.execute_reply":"2023-04-04T19:52:08.405209Z","shell.execute_reply.started":"2023-04-04T19:52:08.398293Z"},"trusted":true},"outputs":[],"source":["# Epsilon value for layer normalisation\n","LAYER_NORM_EPS = 1e-6\n","\n","# Dense layer units for landmarks\n","LIPS_UNITS = 384\n","HANDS_UNITS = 384\n","POSE_UNITS = 384\n","# final embedding and transformer embedding size\n","UNITS = 512\n","\n","# Transformer\n","NUM_BLOCKS = 2\n","MLP_RATIO = 2\n","\n","# Dropout\n","EMBEDDING_DROPOUT = 0.00\n","MLP_DROPOUT_RATIO = 0.30\n","CLASSIFIER_DROPOUT_RATIO = 0.10\n","\n","# Initiailizers\n","INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n","INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n","INIT_ZEROS = tf.keras.initializers.constant(0.0)\n","# Activations\n","GELU = tf.keras.activations.gelu\n","\n","print(f'UNITS: {UNITS}')"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer\n","\n","Need to implement transformer from scratch as TFLite does not support the native TF implementation of MultiHeadAttention."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.410447Z","iopub.status.busy":"2023-04-04T19:52:08.40808Z","iopub.status.idle":"2023-04-04T19:52:08.423049Z","shell.execute_reply":"2023-04-04T19:52:08.421873Z","shell.execute_reply.started":"2023-04-04T19:52:08.410408Z"},"trusted":true},"outputs":[],"source":["# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n","# replaced softmax with softmax layer to support masked softmax\n","def scaled_dot_product(q,k,v, softmax, attention_mask):\n","    #calculates Q . K(transpose)\n","    qkt = tf.matmul(q,k,transpose_b=True)\n","    #caculates scaling factor\n","    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n","    scaled_qkt = qkt/dk\n","    softmax = softmax(scaled_qkt, mask=attention_mask)\n","    \n","    z = tf.matmul(softmax,v)\n","    #shape: (m,Tx,depth), same shape as q,k,v\n","    return z\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self,d_model,num_of_heads):\n","        super(MultiHeadAttention,self).__init__()\n","        self.d_model = d_model\n","        self.num_of_heads = num_of_heads\n","        self.depth = d_model//num_of_heads\n","        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n","        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n","        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n","        self.wo = tf.keras.layers.Dense(d_model)\n","        self.softmax = tf.keras.layers.Softmax()\n","        \n","    def call(self,x, attention_mask):\n","        \n","        multi_attn = []\n","        for i in range(self.num_of_heads):\n","            Q = self.wq[i](x)\n","            K = self.wk[i](x)\n","            V = self.wv[i](x)\n","            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n","            \n","        multi_head = tf.concat(multi_attn,axis=-1)\n","        multi_head_attention = self.wo(multi_head)\n","        return multi_head_attention"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.42538Z","iopub.status.busy":"2023-04-04T19:52:08.424975Z","iopub.status.idle":"2023-04-04T19:52:08.437604Z","shell.execute_reply":"2023-04-04T19:52:08.436622Z","shell.execute_reply.started":"2023-04-04T19:52:08.425325Z"},"trusted":true},"outputs":[],"source":["# Full Transformer\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_blocks):\n","        super(Transformer, self).__init__(name='transformer')\n","        self.num_blocks = num_blocks\n","    \n","    def build(self, input_shape):\n","        self.ln_1s = []\n","        self.mhas = []\n","        self.ln_2s = []\n","        self.mlps = []\n","        # Make Transformer Blocks\n","        for i in range(self.num_blocks):\n","            # Multi Head Attention\n","            self.mhas.append(MultiHeadAttention(UNITS, 8))\n","            # Multi Layer Perception\n","            self.mlps.append(tf.keras.Sequential([\n","                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n","                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n","                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n","            ]))\n","        \n","    def call(self, x, attention_mask):\n","        # Iterate input over transformer blocks\n","        for mha, mlp in zip(self.mhas, self.mlps):\n","            x = x + mha(x, attention_mask)\n","            x = x + mlp(x)\n","    \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Landmark Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.439525Z","iopub.status.busy":"2023-04-04T19:52:08.438902Z","iopub.status.idle":"2023-04-04T19:52:08.45214Z","shell.execute_reply":"2023-04-04T19:52:08.451179Z","shell.execute_reply.started":"2023-04-04T19:52:08.439482Z"},"trusted":true},"outputs":[],"source":["class LandmarkEmbedding(tf.keras.Model):\n","    def __init__(self, units, name):\n","        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n","        self.units = units\n","        \n","    def build(self, input_shape):\n","        # Embedding for missing landmark in frame, initizlied with zeros\n","        self.empty_embedding = self.add_weight(\n","            name=f'{self.name}_empty_embedding',\n","            shape=[self.units],\n","            initializer=INIT_ZEROS,\n","        )\n","        # Embedding\n","        self.dense = tf.keras.Sequential([\n","            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n","            tf.keras.layers.Activation(GELU),\n","            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n","        ], name=f'{self.name}_dense')\n","\n","    def call(self, x):\n","        return tf.where(\n","                # Checks whether landmark is missing in frame\n","                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n","                # If so, the empty embedding is used\n","                self.empty_embedding,\n","                # Otherwise the landmark data is embedded\n","                self.dense(x),\n","            )"]},{"cell_type":"markdown","metadata":{},"source":["# Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.454076Z","iopub.status.busy":"2023-04-04T19:52:08.453664Z","iopub.status.idle":"2023-04-04T19:52:08.469826Z","shell.execute_reply":"2023-04-04T19:52:08.468555Z","shell.execute_reply.started":"2023-04-04T19:52:08.454033Z"},"trusted":true},"outputs":[],"source":["class Embedding(tf.keras.Model):\n","    def __init__(self):\n","        super(Embedding, self).__init__()\n","        \n","    def get_diffs(self, l):\n","        S = l.shape[2]\n","        other = tf.expand_dims(l, 3)\n","        other = tf.repeat(other, S, axis=3)\n","        other = tf.transpose(other, [0,1,3,2])\n","        diffs = tf.expand_dims(l, 3) - other\n","        diffs = tf.reshape(diffs, [-1, INPUT_SIZE, S*S])\n","        return diffs\n","\n","    def build(self, input_shape):\n","        # Positional Embedding, initialized with zeros\n","        self.positional_embedding = tf.keras.layers.Embedding(INPUT_SIZE+1, UNITS, embeddings_initializer=INIT_ZEROS)\n","        # Embedding layer for Landmarks\n","        self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n","        self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n","        self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n","        # Landmark Weights\n","        self.landmark_weights = tf.Variable(tf.zeros([3], dtype=tf.float32), name='landmark_weights')\n","        # Fully Connected Layers for combined landmarks\n","        self.fc = tf.keras.Sequential([\n","            tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM),\n","            tf.keras.layers.Activation(GELU),\n","            tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n","        ], name='fc')\n","\n","\n","    def call(self, lips0, left_hand0, pose0, non_empty_frame_idxs, training=False):\n","        # Lips\n","        lips_embedding = self.lips_embedding(lips0)\n","        # Left Hand\n","        left_hand_embedding = self.left_hand_embedding(left_hand0)\n","        # Pose\n","        pose_embedding = self.pose_embedding(pose0)\n","        # Merge Embeddings of all landmarks with mean pooling\n","        x = tf.stack((\n","            lips_embedding, left_hand_embedding, pose_embedding,\n","        ), axis=3)\n","        x = x * tf.nn.softmax(self.landmark_weights)\n","        x = tf.reduce_sum(x, axis=3)\n","        # Fully Connected Layers\n","        x = self.fc(x)\n","        # Add Positional Embedding\n","        max_frame_idxs = tf.clip_by_value(\n","                tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True),\n","                1,\n","                np.PINF,\n","            )\n","        normalised_non_empty_frame_idxs = tf.where(\n","            tf.math.equal(non_empty_frame_idxs, -1.0),\n","            INPUT_SIZE,\n","            tf.cast(\n","                non_empty_frame_idxs / max_frame_idxs * INPUT_SIZE,\n","                tf.int32,\n","            ),\n","        )\n","        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.47183Z","iopub.status.busy":"2023-04-04T19:52:08.471483Z","iopub.status.idle":"2023-04-04T19:52:08.482779Z","shell.execute_reply":"2023-04-04T19:52:08.48186Z","shell.execute_reply.started":"2023-04-04T19:52:08.471792Z"},"trusted":true},"outputs":[],"source":["# Not used, adds random X/y translation to input on samples level\n","class Augmentation(tf.keras.layers.Layer):\n","    def __init__(self, noise_std):\n","        super(Augmentation, self).__init__()\n","        self.noise_std = noise_std\n","    \n","    def add_noise(self, t):\n","        B = tf.shape(t)[0]\n","        return tf.where(\n","            t == 0.0,\n","            0.0,\n","            t + tf.random.normal([B,1,1,tf.shape(t)[3]], 0, self.noise_std),\n","        )\n","    \n","    def call(self, lips0, left_hand0, pose0, training=False):\n","        if training:\n","            # Lips\n","            lips0 = self.add_noise(lips0)\n","            # Left Hand\n","            left_hand0 = self.add_noise(left_hand0)\n","            # Pose\n","            pose0 = self.add_noise(pose0)\n","        \n","        return lips0, left_hand0, pose0"]},{"cell_type":"markdown","metadata":{},"source":["# Sparse Categorical Crossentropy With Label Smoothing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.484928Z","iopub.status.busy":"2023-04-04T19:52:08.484263Z","iopub.status.idle":"2023-04-04T19:52:08.496196Z","shell.execute_reply":"2023-04-04T19:52:08.495394Z","shell.execute_reply.started":"2023-04-04T19:52:08.484889Z"},"trusted":true},"outputs":[],"source":["# source:: https://stackoverflow.com/questions/60689185/label-smoothing-for-sparse-categorical-crossentropy\n","def scce_with_ls(y_true, y_pred):\n","    # One Hot Encode Sparsely Encoded Target Sign\n","    y_true = tf.cast(y_true, tf.int32)\n","    y_true = tf.one_hot(y_true, NUM_CLASSES, axis=1)\n","    y_true = tf.squeeze(y_true, axis=2)\n","    # Categorical Crossentropy with native label smoothing support\n","    return tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing=0.25)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.498003Z","iopub.status.busy":"2023-04-04T19:52:08.497481Z","iopub.status.idle":"2023-04-04T19:52:08.515927Z","shell.execute_reply":"2023-04-04T19:52:08.515188Z","shell.execute_reply.started":"2023-04-04T19:52:08.497963Z"},"trusted":true},"outputs":[],"source":["def get_model():\n","    # Inputs\n","    frames = tf.keras.layers.Input([INPUT_SIZE, N_COLS, N_DIMS], dtype=tf.float32, name='frames')\n","    non_empty_frame_idxs = tf.keras.layers.Input([INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n","    # Padding Mask\n","    mask0 = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n","    mask0 = tf.expand_dims(mask0, axis=2)\n","    # Random Frame Masking\n","    mask = tf.where(\n","        (tf.random.uniform(tf.shape(mask0)) > 0.25) & tf.math.not_equal(mask0, 0.0),\n","        1.0,\n","        0.0,\n","    )\n","    # Correct Samples Which are all masked now...\n","    mask = tf.where(\n","        tf.math.equal(tf.reduce_sum(mask, axis=[1,2], keepdims=True), 0.0),\n","        mask0,\n","        mask,\n","    )\n","    \n","    \n","    \"\"\"\n","        left_hand: 468:489\n","        pose: 489:522\n","        right_hand: 522:543\n","    \"\"\"\n","    x = frames\n","    x = tf.slice(x, [0,0,0,0], [-1,INPUT_SIZE, N_COLS, 2])\n","    # LIPS\n","    lips = tf.slice(x, [0,0,LIPS_START,0], [-1,INPUT_SIZE, 40, 2])\n","    lips = tf.where(\n","            tf.math.equal(lips, 0.0),\n","            0.0,\n","            (lips - LIPS_MEAN) / LIPS_STD,\n","        )\n","    # LEFT HAND\n","    left_hand = tf.slice(x, [0,0,40,0], [-1,INPUT_SIZE, 21, 2])\n","    left_hand = tf.where(\n","            tf.math.equal(left_hand, 0.0),\n","            0.0,\n","            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n","        )\n","    # POSE\n","    pose = tf.slice(x, [0,0,61,0], [-1,INPUT_SIZE, 5, 2])\n","    pose = tf.where(\n","            tf.math.equal(pose, 0.0),\n","            0.0,\n","            (pose - POSE_MEAN) / POSE_STD,\n","        )\n","    \n","    # Flatten\n","    lips = tf.reshape(lips, [-1, INPUT_SIZE, 40*2])\n","    left_hand = tf.reshape(left_hand, [-1, INPUT_SIZE, 21*2])\n","    pose = tf.reshape(pose, [-1, INPUT_SIZE, 5*2])\n","        \n","    # Embedding\n","    x = Embedding()(lips, left_hand, pose, non_empty_frame_idxs)\n","    \n","    # Encoder Transformer Blocks\n","    x = Transformer(NUM_BLOCKS)(x, mask)\n","    \n","    # Pooling\n","    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n","    # Classifier Dropout\n","    x = tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO)(x)\n","    # Classification Layer\n","    x = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n","    \n","    outputs = x\n","    \n","    # Create Tensorflow Model\n","    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n","    \n","    # Sparse Categorical Cross Entropy With Label Smoothing\n","    loss = scce_with_ls\n","    \n","    # Adam Optimizer with weight decay\n","    optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n","    \n","    # TopK Metrics\n","    metrics = [\n","        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n","        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_acc'),\n","        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name='top_10_acc'),\n","    ]\n","    \n","    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:08.517634Z","iopub.status.busy":"2023-04-04T19:52:08.516991Z","iopub.status.idle":"2023-04-04T19:52:10.655405Z","shell.execute_reply":"2023-04-04T19:52:10.654294Z","shell.execute_reply.started":"2023-04-04T19:52:08.517597Z"},"trusted":true},"outputs":[],"source":["tf.keras.backend.clear_session()\n","\n","model = get_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:10.657013Z","iopub.status.busy":"2023-04-04T19:52:10.656669Z","iopub.status.idle":"2023-04-04T19:52:10.835039Z","shell.execute_reply":"2023-04-04T19:52:10.834017Z","shell.execute_reply.started":"2023-04-04T19:52:10.656978Z"},"trusted":true},"outputs":[],"source":["# Plot model summary\n","model.summary(expand_nested=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:10.83676Z","iopub.status.busy":"2023-04-04T19:52:10.836408Z","iopub.status.idle":"2023-04-04T19:52:12.239767Z","shell.execute_reply":"2023-04-04T19:52:12.238557Z","shell.execute_reply.started":"2023-04-04T19:52:10.836722Z"},"trusted":true},"outputs":[],"source":["tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"]},{"cell_type":"markdown","metadata":{},"source":["# No NaN Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:12.242646Z","iopub.status.busy":"2023-04-04T19:52:12.241535Z","iopub.status.idle":"2023-04-04T19:52:16.140534Z","shell.execute_reply":"2023-04-04T19:52:16.138946Z","shell.execute_reply.started":"2023-04-04T19:52:12.242586Z"},"trusted":true},"outputs":[],"source":["if not PREPROCESS_DATA and TRAIN_MODEL:\n","    y_pred = model.predict_on_batch(X_batch).flatten()\n","\n","    print(f'# NaN Values In Prediction: {np.isnan(y_pred).sum()}')"]},{"cell_type":"markdown","metadata":{},"source":["# Weight Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:16.143288Z","iopub.status.busy":"2023-04-04T19:52:16.142483Z","iopub.status.idle":"2023-04-04T19:52:16.731487Z","shell.execute_reply":"2023-04-04T19:52:16.728612Z","shell.execute_reply.started":"2023-04-04T19:52:16.143225Z"},"trusted":true},"outputs":[],"source":["if not PREPROCESS_DATA and TRAIN_MODEL:\n","    plt.figure(figsize=(12,5))\n","    plt.title(f'Softmax Output Initialized Model | µ={y_pred.mean():.3f}, σ={y_pred.std():.3f}', pad=25)\n","    pd.Series(y_pred).plot(kind='hist', bins=128, label='Class Probability')\n","    plt.xlim(0, max(y_pred) * 1.1)\n","    plt.vlines([1 / NUM_CLASSES], 0, plt.ylim()[1], color='red', label=f'Random Guessing Baseline 1/NUM_CLASSES={1 / NUM_CLASSES:.3f}')\n","    plt.grid()\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Learning Rate Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:16.733737Z","iopub.status.busy":"2023-04-04T19:52:16.733041Z","iopub.status.idle":"2023-04-04T19:52:16.742972Z","shell.execute_reply":"2023-04-04T19:52:16.741197Z","shell.execute_reply.started":"2023-04-04T19:52:16.733695Z"},"trusted":true},"outputs":[],"source":["def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n","    \n","    if current_step < num_warmup_steps:\n","        if WARMUP_METHOD == 'log':\n","            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n","        else:\n","            return lr_max * 2 ** -(num_warmup_steps - current_step)\n","    else:\n","        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","\n","        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:16.744969Z","iopub.status.busy":"2023-04-04T19:52:16.744263Z","iopub.status.idle":"2023-04-04T19:52:17.502416Z","shell.execute_reply":"2023-04-04T19:52:17.501311Z","shell.execute_reply.started":"2023-04-04T19:52:16.744929Z"},"trusted":true},"outputs":[],"source":["def plot_lr_schedule(lr_schedule, epochs):\n","    fig = plt.figure(figsize=(20, 10))\n","    plt.plot([None] + lr_schedule + [None])\n","    # X Labels\n","    x = np.arange(1, epochs + 1)\n","    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n","    plt.xlim([1, epochs])\n","    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n","    \n","    # Increase y-limit for better readability\n","    plt.ylim([0, max(lr_schedule) * 1.1])\n","    \n","    # Title\n","    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n","    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n","    \n","    # Plot Learning Rates\n","    for x, val in enumerate(lr_schedule):\n","        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n","            if x < len(lr_schedule) - 1:\n","                if lr_schedule[x - 1] < val:\n","                    ha = 'right'\n","                else:\n","                    ha = 'left'\n","            elif x == 0:\n","                ha = 'right'\n","            else:\n","                ha = 'left'\n","            plt.plot(x + 1, val, 'o', color='black');\n","            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n","            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n","    \n","    plt.xlabel('Epoch', size=16, labelpad=5)\n","    plt.ylabel('Learning Rate', size=16, labelpad=5)\n","    plt.grid()\n","    plt.show()\n","\n","# Learning rate for encoder\n","LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n","# Plot Learning Rate Schedule\n","plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n","# Learning Rate Callback\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)"]},{"cell_type":"markdown","metadata":{},"source":["# Weight Decay Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:17.504927Z","iopub.status.busy":"2023-04-04T19:52:17.503834Z","iopub.status.idle":"2023-04-04T19:52:17.512621Z","shell.execute_reply":"2023-04-04T19:52:17.511453Z","shell.execute_reply.started":"2023-04-04T19:52:17.504881Z"},"trusted":true},"outputs":[],"source":["# Custom callback to update weight decay with learning rate\n","class WeightDecayCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, wd_ratio=WD_RATIO):\n","        self.step_counter = 0\n","        self.wd_ratio = wd_ratio\n","    \n","    def on_epoch_begin(self, epoch, logs=None):\n","        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n","        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"]},{"cell_type":"markdown","metadata":{},"source":["# Performance Benchmark"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:17.515297Z","iopub.status.busy":"2023-04-04T19:52:17.514364Z","iopub.status.idle":"2023-04-04T19:52:30.343614Z","shell.execute_reply":"2023-04-04T19:52:30.342517Z","shell.execute_reply.started":"2023-04-04T19:52:17.515229Z"},"trusted":true},"outputs":[],"source":["%%timeit -n 100\n","if TRAIN_MODEL:\n","    # Verify model prediction is <<<100ms\n","    model.predict_on_batch({ 'frames': X_train[:1], 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_TRAIN[:1] })\n","    pass"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:30.346005Z","iopub.status.busy":"2023-04-04T19:52:30.345604Z","iopub.status.idle":"2023-04-04T19:52:30.3612Z","shell.execute_reply":"2023-04-04T19:52:30.359736Z","shell.execute_reply.started":"2023-04-04T19:52:30.345963Z"},"trusted":true},"outputs":[],"source":["if USE_VAL:\n","    # Verify Validation Dataset Covers All Signs\n","    print(f'# Unique Signs in Validation Set: {pd.Series(y_val).nunique()}')\n","    # Value Counts\n","    display(pd.Series(y_val).value_counts().to_frame('Count').iloc[[1,2,3,-3,-2,-1]])"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate Initialzied Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:30.36326Z","iopub.status.busy":"2023-04-04T19:52:30.362703Z","iopub.status.idle":"2023-04-04T19:52:40.649622Z","shell.execute_reply":"2023-04-04T19:52:40.648608Z","shell.execute_reply.started":"2023-04-04T19:52:30.363199Z"},"trusted":true},"outputs":[],"source":["# Sanity Check\n","if TRAIN_MODEL and USE_VAL:\n","    _ = model.evaluate(*validation_data, verbose=2)"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:52:40.651692Z","iopub.status.busy":"2023-04-04T19:52:40.651158Z","iopub.status.idle":"2023-04-04T19:56:18.533255Z","shell.execute_reply":"2023-04-04T19:56:18.531296Z","shell.execute_reply.started":"2023-04-04T19:52:40.651644Z"},"trusted":true},"outputs":[],"source":["if TRAIN_MODEL:\n","    # Clear all models in GPU\n","    tf.keras.backend.clear_session()\n","\n","    # Get new fresh model\n","    model = get_model()\n","    \n","    # Sanity Check\n","    model.summary()\n","\n","    # Actual Training\n","    history = model.fit(\n","            x=get_train_batch_all_signs(X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN),\n","            steps_per_epoch=len(X_train) // (NUM_CLASSES * BATCH_ALL_SIGNS_N),\n","            epochs=N_EPOCHS,\n","            # Only used for validation data since training data is a generator\n","            batch_size=BATCH_SIZE,\n","            validation_data=validation_data,\n","            callbacks=[\n","                lr_callback,\n","                WeightDecayCallback(),\n","            ],\n","            verbose = VERBOSE,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:23.992374Z","iopub.status.busy":"2023-04-04T19:56:23.99192Z","iopub.status.idle":"2023-04-04T19:56:24.169712Z","shell.execute_reply":"2023-04-04T19:56:24.168655Z","shell.execute_reply.started":"2023-04-04T19:56:23.992334Z"},"trusted":true},"outputs":[],"source":["# Save Model Weights\n","model.save_weights('model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:24.275446Z","iopub.status.busy":"2023-04-04T19:56:24.274905Z","iopub.status.idle":"2023-04-04T19:56:35.370383Z","shell.execute_reply":"2023-04-04T19:56:35.369269Z","shell.execute_reply.started":"2023-04-04T19:56:24.275408Z"},"trusted":true},"outputs":[],"source":["if USE_VAL:\n","    # Validation Predictions\n","    y_val_pred = model.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n","    # Label\n","    labels = [ORD2SIGN.get(i).replace(' ', '_') for i in range(NUM_CLASSES)]"]},{"cell_type":"markdown","metadata":{},"source":["# Landmark Attention Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:35.372566Z","iopub.status.busy":"2023-04-04T19:56:35.372191Z","iopub.status.idle":"2023-04-04T19:56:35.382927Z","shell.execute_reply":"2023-04-04T19:56:35.381628Z","shell.execute_reply.started":"2023-04-04T19:56:35.372536Z"},"trusted":true},"outputs":[],"source":["# Landmark Weights\n","for w in model.get_layer('embedding').weights:\n","    if 'landmark_weights' in w.name:\n","        weights = scipy.special.softmax(w)\n","\n","landmarks = ['lips_embedding', 'left_hand_embedding', 'pose_embedding']\n","\n","for w, lm in zip(weights, landmarks):\n","    print(f'{lm} weight: {(w*100):.1f}%')"]},{"cell_type":"markdown","metadata":{},"source":["# Classification Report"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:35.385682Z","iopub.status.busy":"2023-04-04T19:56:35.384825Z","iopub.status.idle":"2023-04-04T19:56:35.396987Z","shell.execute_reply":"2023-04-04T19:56:35.395901Z","shell.execute_reply.started":"2023-04-04T19:56:35.385631Z"},"trusted":true},"outputs":[],"source":["def print_classification_report():\n","    # Classification report for all signs\n","    classification_report = sklearn.metrics.classification_report(\n","            y_val,\n","            y_val_pred,\n","            target_names=labels,\n","            output_dict=True,\n","        )\n","    # Round Data for better readability\n","    classification_report = pd.DataFrame(classification_report).T\n","    classification_report = classification_report.round(2)\n","    classification_report = classification_report.astype({\n","            'support': np.uint16,\n","        })\n","    # Add signs\n","    classification_report['sign'] = [e if e in SIGN2ORD else -1 for e in classification_report.index]\n","    classification_report['sign_ord'] = classification_report['sign'].apply(SIGN2ORD.get).fillna(-1).astype(np.int16)\n","    # Sort on F1-score\n","    classification_report = pd.concat((\n","        classification_report.head(NUM_CLASSES).sort_values('f1-score', ascending=False),\n","        classification_report.tail(3),\n","    ))\n","\n","    pd.options.display.max_rows = 999\n","    display(classification_report)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:35.401467Z","iopub.status.busy":"2023-04-04T19:56:35.401015Z","iopub.status.idle":"2023-04-04T19:56:35.549772Z","shell.execute_reply":"2023-04-04T19:56:35.548312Z","shell.execute_reply.started":"2023-04-04T19:56:35.401429Z"},"trusted":true},"outputs":[],"source":["if USE_VAL:\n","    print_classification_report()"]},{"cell_type":"markdown","metadata":{},"source":["# Training History"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:56:18.54774Z","iopub.status.idle":"2023-04-04T19:56:18.548633Z","shell.execute_reply":"2023-04-04T19:56:18.548392Z","shell.execute_reply.started":"2023-04-04T19:56:18.548365Z"},"trusted":true},"outputs":[],"source":["def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n","    plt.figure(figsize=(20, 10))\n","    \n","    values = history.history[metric]\n","    N_EPOCHS = len(values)\n","    val = 'val' in ''.join(history.history.keys())\n","    # Epoch Ticks\n","    if N_EPOCHS <= 20:\n","        x = np.arange(1, N_EPOCHS + 1)\n","    else:\n","        x = [1, 5] + [10 + 5 * idx for idx in range((N_EPOCHS - 10) // 5 + 1)]\n","\n","    x_ticks = np.arange(1, N_EPOCHS+1)\n","\n","    # Validation\n","    if val:\n","        val_values = history.history[f'val_{metric}']\n","        val_argmin = f_best(val_values)\n","        plt.plot(x_ticks, val_values, label=f'val')\n","\n","    # summarize history for accuracy\n","    plt.plot(x_ticks, values, label=f'train')\n","    argmin = f_best(values)\n","    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n","    if val:\n","        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n","\n","    plt.title(f'Model {metric}', fontsize=24, pad=10)\n","    plt.ylabel(metric, fontsize=20, labelpad=10)\n","\n","    if ylim:\n","        plt.ylim(ylim)\n","\n","    if yscale is not None:\n","        plt.yscale(yscale)\n","        \n","    if yticks is not None:\n","        plt.yticks(yticks, fontsize=16)\n","\n","    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n","    plt.tick_params(axis='x', labelsize=8)\n","    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n","    plt.yticks(fontsize=16)\n","    \n","    plt.legend(prop={'size': 10})\n","    plt.grid()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:56:18.550176Z","iopub.status.idle":"2023-04-04T19:56:18.551046Z","shell.execute_reply":"2023-04-04T19:56:18.550791Z","shell.execute_reply.started":"2023-04-04T19:56:18.550765Z"},"trusted":true},"outputs":[],"source":["if TRAIN_MODEL:\n","    plot_history_metric('loss', f_best=np.argmin)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:56:18.552699Z","iopub.status.idle":"2023-04-04T19:56:18.5536Z","shell.execute_reply":"2023-04-04T19:56:18.553366Z","shell.execute_reply.started":"2023-04-04T19:56:18.553339Z"},"trusted":true},"outputs":[],"source":["if TRAIN_MODEL:\n","    plot_history_metric('acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:56:18.555073Z","iopub.status.idle":"2023-04-04T19:56:18.555921Z","shell.execute_reply":"2023-04-04T19:56:18.555666Z","shell.execute_reply.started":"2023-04-04T19:56:18.55564Z"},"trusted":true},"outputs":[],"source":["if TRAIN_MODEL:\n","    plot_history_metric('top_5_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:56:18.557925Z","iopub.status.idle":"2023-04-04T19:56:18.558843Z","shell.execute_reply":"2023-04-04T19:56:18.55854Z","shell.execute_reply.started":"2023-04-04T19:56:18.558513Z"},"trusted":true},"outputs":[],"source":["if TRAIN_MODEL:\n","    plot_history_metric('top_10_acc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:35.552287Z","iopub.status.busy":"2023-04-04T19:56:35.551772Z","iopub.status.idle":"2023-04-04T19:56:37.663296Z","shell.execute_reply":"2023-04-04T19:56:37.662025Z","shell.execute_reply.started":"2023-04-04T19:56:35.552229Z"},"trusted":true},"outputs":[],"source":["# TFLite model for submission\n","class TFLiteModel(tf.Module):\n","    def __init__(self, model):\n","        super(TFLiteModel, self).__init__()\n","\n","        # Load the feature generation and main models\n","        self.preprocess_layer = preprocess_layer\n","        self.model = model\n","    \n","    @tf.function(input_signature=[tf.TensorSpec(shape=[None, N_ROWS, N_DIMS], dtype=tf.float32, name='inputs')])\n","    def __call__(self, inputs):\n","        # Preprocess Data\n","        x, non_empty_frame_idxs = self.preprocess_layer(inputs)\n","        # Add Batch Dimension\n","        x = tf.expand_dims(x, axis=0)\n","        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n","        # Make Prediction\n","        outputs = self.model({ 'frames': x, 'non_empty_frame_idxs': non_empty_frame_idxs })\n","        # Squeeze Output 1x250 -> 250\n","        outputs = tf.squeeze(outputs, axis=0)\n","\n","        # Return a dictionary with the output tensor\n","        return {'outputs': outputs}\n","\n","# Define TF Lite Model\n","tflite_keras_model = TFLiteModel(model)\n","\n","# Sanity Check\n","demo_raw_data = load_relevant_data_subset(train['file_path'].values[5])\n","print(f'demo_raw_data shape: {demo_raw_data.shape}, dtype: {demo_raw_data.dtype}')\n","demo_output = tflite_keras_model(demo_raw_data)[\"outputs\"]\n","print(f'demo_output shape: {demo_output.shape}, dtype: {demo_output.dtype}')\n","demo_prediction = demo_output.numpy().argmax()\n","print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[0][\"sign_ord\"]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:56:37.665271Z","iopub.status.busy":"2023-04-04T19:56:37.66495Z","iopub.status.idle":"2023-04-04T19:57:20.503604Z","shell.execute_reply":"2023-04-04T19:57:20.501942Z","shell.execute_reply.started":"2023-04-04T19:56:37.665222Z"},"trusted":true},"outputs":[],"source":["# Create Model Converter\n","keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n","# Convert Model\n","tflite_model = keras_model_converter.convert()\n","# Write Model\n","with open('/kaggle/working/model.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","    \n","# Zip Model\n","!zip submission.zip /kaggle/working/model.tflite"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-04T19:57:20.50757Z","iopub.status.busy":"2023-04-04T19:57:20.505939Z","iopub.status.idle":"2023-04-04T19:57:32.619986Z","shell.execute_reply":"2023-04-04T19:57:32.618407Z","shell.execute_reply.started":"2023-04-04T19:57:20.507511Z"},"trusted":true},"outputs":[],"source":["# Verify TFLite model can be loaded and used for prediction\n","!pip install tflite-runtime\n","import tflite_runtime.interpreter as tflite\n","\n","interpreter = tflite.Interpreter(\"/kaggle/working/model.tflite\")\n","found_signatures = list(interpreter.get_signature_list().keys())\n","prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n","\n","output = prediction_fn(inputs=demo_raw_data)\n","sign = output['outputs'].argmax()\n","\n","print(\"PRED : \", ORD2SIGN.get(sign), f'[{sign}]')\n","print(\"TRUE : \", train.sign.values[0], f'[{train.sign_ord.values[0]}]')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
