{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nbformat\n",
    "import tensorflow as tf\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frame_landmark_df(results, frame, xyz):\n",
    "    xyz_skel = xyz[['type','landmark_index']].drop_duplicates().reset_index(drop=True).copy()\n",
    "\n",
    "    face = pd.DataFrame()\n",
    "    pose = pd.DataFrame()\n",
    "    left_hand = pd.DataFrame()\n",
    "    right_hand = pd.DataFrame()\n",
    "    if results.face_landmarks:\n",
    "        for i, point in enumerate(results.face_landmarks.landmark):\n",
    "            face.loc[i, ['x','y','z']] = [point.x, point.y, point.z]\n",
    "    if results.pose_landmarks:\n",
    "        for i , point in enumerate(results.pose_landmarks.landmark):\n",
    "            pose.loc[i, ['x', 'y', 'z']] = [point.x, point.y, point.z]\n",
    "    if results.left_hand_landmarks:\n",
    "        for i, point in enumerate(results.left_hand_landmarks.landmark):\n",
    "            left_hand.loc[i, ['x','y','z']] = [point.x, point.y, point.z]\n",
    "    if results.right_hand_landmarks:\n",
    "        for i, point in enumerate(results.right_hand_landmarks.landmark):\n",
    "            right_hand.loc[i, ['x', 'y', 'z']] = [point.x, point.y, point.z]   \n",
    "    face = face.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='face')\n",
    "    pose = pose.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='pose')\n",
    "    left_hand = left_hand.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='left_hand')\n",
    "    right_hand = right_hand.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='right_hand')\n",
    "\n",
    "\n",
    "    landmarks = pd.concat([face,pose,right_hand,left_hand]).reset_index(drop=True)\n",
    "    landmarks = xyz_skel.merge(landmarks, on=['type','landmark_index'], how='left')\n",
    "    landmarks = landmarks.assign(frame=frame)\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "\n",
    "def do_capture_loop(xyz):\n",
    "    all_landmarks = []\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "        frame = 0\n",
    "        while cap.isOpened():\n",
    "            frame+=1\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(image)\n",
    "\n",
    "        ## create landmarks dataframe from results\n",
    "            landmarks = create_frame_landmark_df(results,frame,xyz)\n",
    "            all_landmarks.append(landmarks)\n",
    "        \n",
    "        # Draw landmark annotation on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.face_landmarks,\n",
    "                mp_holistic.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.pose_landmarks,\n",
    "                mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles\n",
    "                .get_default_pose_landmarks_style())\n",
    "            #Flip the image horizontally for a selfie-view display.\n",
    "            \n",
    "            # text = prediction_func(pq_file)\n",
    "            # print(text)\n",
    "            # draw_predictions(image,text)\n",
    "            # cv2.rectangle(frame, (x, y - text_height - 5), (x + text_width, y), (0, 0, 0), -1)\n",
    "            # cv2.putText(image, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "    # cap.release()\n",
    "    return all_landmarks\n",
    "pq_file_sample = \"train_landmark_files/16069/100015657.parquet\"\n",
    "xyz = pd.read_parquet(pq_file_sample)\n",
    "landmarks = do_capture_loop(xyz)\n",
    "pd.concat(landmarks).reset_index(drop=True).to_parquet('output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nbformat\n",
    "import tensorflow as tf\n",
    "\n",
    "# def prediction_func(pq_file):\n",
    "\n",
    "#     ## defining the model \n",
    "#     interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "#     found_signatures = list(interpreter.get_signature_list().keys())\n",
    "#     prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "    \n",
    "#     # Add ordinally Encoded Sign (assign number to each sign name)\\\n",
    "#     train = pd.read_csv('train.csv.zip')\n",
    "#     train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "#     # Dictionaries to translate sign <-> ordinal encoded sign\n",
    "#     SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "#     ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()\n",
    "\n",
    "#     ## load data from output parquet\n",
    "#     xyz_np = load_relevant_data_subset(pq_file)\n",
    "#     prediction = prediction_fn(inputs=xyz_np)\n",
    "#     sign = prediction['outputs'].argmax()\n",
    "#     return ORD2SIGN[sign]\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "\n",
    "def create_frame_landmark_df(results, frame, xyz):\n",
    "    xyz_skel = xyz[['type','landmark_index']].drop_duplicates().reset_index(drop=True).copy()\n",
    "\n",
    "    face = pd.DataFrame()\n",
    "    pose = pd.DataFrame()\n",
    "    left_hand = pd.DataFrame()\n",
    "    right_hand = pd.DataFrame()\n",
    "    if results.face_landmarks:\n",
    "        for i, point in enumerate(results.face_landmarks.landmark):\n",
    "            face.loc[i, ['x','y','z']] = [point.x, point.y, point.z]\n",
    "    if results.pose_landmarks:\n",
    "        for i , point in enumerate(results.pose_landmarks.landmark):\n",
    "            pose.loc[i, ['x', 'y', 'z']] = [point.x, point.y, point.z]\n",
    "    if results.left_hand_landmarks:\n",
    "        for i, point in enumerate(results.left_hand_landmarks.landmark):\n",
    "            left_hand.loc[i, ['x','y','z']] = [point.x, point.y, point.z]\n",
    "    if results.right_hand_landmarks:\n",
    "        for i, point in enumerate(results.right_hand_landmarks.landmark):\n",
    "            right_hand.loc[i, ['x', 'y', 'z']] = [point.x, point.y, point.z]   \n",
    "    face = face.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='face')\n",
    "    pose = pose.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='pose')\n",
    "    left_hand = left_hand.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='left_hand')\n",
    "    right_hand = right_hand.reset_index() \\\n",
    "        .rename(columns={'index':'landmark_index'}) \\\n",
    "            .assign(type='right_hand')\n",
    "\n",
    "\n",
    "    landmarks = pd.concat([face,pose,right_hand,left_hand]).reset_index(drop=True)\n",
    "    landmarks = xyz_skel.merge(landmarks, on=['type','landmark_index'], how='left')\n",
    "    landmarks = landmarks.assign(frame=frame)\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "# For webcam input:\n",
    "def do_capture_loop(xyz):\n",
    "    all_landmarks = []\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "        frame = 0\n",
    "        while cap.isOpened():\n",
    "            frame+=1\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(image)\n",
    "\n",
    "        ## create landmarks dataframe from results\n",
    "            landmarks = create_frame_landmark_df(results,frame,xyz)\n",
    "            all_landmarks.append(landmarks)\n",
    "        \n",
    "        # Draw landmark annotation on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.face_landmarks,\n",
    "                mp_holistic.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_contours_style())\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.pose_landmarks,\n",
    "                mp_holistic.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles\n",
    "                .get_default_pose_landmarks_style())\n",
    "            #Flip the image horizontally for a selfie-view display.\n",
    "            \n",
    "            # text = prediction_func(pq_file)\n",
    "            # print(text)\n",
    "            # draw_predictions(image,text)\n",
    "            # cv2.rectangle(frame, (x, y - text_height - 5), (x + text_width, y), (0, 0, 0), -1)\n",
    "            # cv2.putText(image, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "    # cap.release()\n",
    "    return all_landmarks\n",
    "pq_file_sample = \"train_landmark_files/16069/100015657.parquet\"\n",
    "xyz = pd.read_parquet(pq_file_sample)\n",
    "landmarks = do_capture_loop(xyz)\n",
    "pd.concat(landmarks).reset_index(drop=True).to_parquet('output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pq_file = \"output.parquet\"\n",
    "def prediction_func(pq_file):\n",
    "\n",
    "    ## defining the model \n",
    "    interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "    found_signatures = list(interpreter.get_signature_list().keys())\n",
    "    prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "    \n",
    "    # Add ordinally Encoded Sign (assign number to each sign name)\\\n",
    "    train = pd.read_csv('train.csv.zip')\n",
    "    train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "    # Dictionaries to translate sign <-> ordinal encoded sign\n",
    "    SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "    ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()\n",
    "\n",
    "    ## load data from output parquet\n",
    "    xyz_np = load_relevant_data_subset(pq_file)\n",
    "    prediction = prediction_fn(inputs=xyz_np)\n",
    "    sign = prediction['outputs'].argmax()\n",
    "    return ORD2SIGN[sign]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shhh'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_func(pq_file=\"output.parquet\")\n",
    "# pd.Series(prediction['outputs']).plot(figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>train_landmark_files/37055/1003109377.parquet</td>\n",
       "      <td>37055</td>\n",
       "      <td>1003109377</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>train_landmark_files/18796/1017029978.parquet</td>\n",
       "      <td>18796</td>\n",
       "      <td>1017029978</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>train_landmark_files/18796/1023157153.parquet</td>\n",
       "      <td>18796</td>\n",
       "      <td>1023157153</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>train_landmark_files/18796/1029866550.parquet</td>\n",
       "      <td>18796</td>\n",
       "      <td>1029866550</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>train_landmark_files/4718/1030999521.parquet</td>\n",
       "      <td>4718</td>\n",
       "      <td>1030999521</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93588</th>\n",
       "      <td>train_landmark_files/36257/962546588.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>962546588</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93982</th>\n",
       "      <td>train_landmark_files/37779/979999637.parquet</td>\n",
       "      <td>37779</td>\n",
       "      <td>979999637</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94031</th>\n",
       "      <td>train_landmark_files/37055/981603802.parquet</td>\n",
       "      <td>37055</td>\n",
       "      <td>981603802</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94376</th>\n",
       "      <td>train_landmark_files/25571/99567121.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>99567121</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94398</th>\n",
       "      <td>train_landmark_files/27610/996627508.parquet</td>\n",
       "      <td>27610</td>\n",
       "      <td>996627508</td>\n",
       "      <td>shhh</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "79     train_landmark_files/37055/1003109377.parquet           37055   \n",
       "418    train_landmark_files/18796/1017029978.parquet           18796   \n",
       "546    train_landmark_files/18796/1023157153.parquet           18796   \n",
       "705    train_landmark_files/18796/1029866550.parquet           18796   \n",
       "732     train_landmark_files/4718/1030999521.parquet            4718   \n",
       "...                                              ...             ...   \n",
       "93588   train_landmark_files/36257/962546588.parquet           36257   \n",
       "93982   train_landmark_files/37779/979999637.parquet           37779   \n",
       "94031   train_landmark_files/37055/981603802.parquet           37055   \n",
       "94376    train_landmark_files/25571/99567121.parquet           25571   \n",
       "94398   train_landmark_files/27610/996627508.parquet           27610   \n",
       "\n",
       "       sequence_id  sign  sign_ord  \n",
       "79      1003109377  shhh       194  \n",
       "418     1017029978  shhh       194  \n",
       "546     1023157153  shhh       194  \n",
       "705     1029866550  shhh       194  \n",
       "732     1030999521  shhh       194  \n",
       "...            ...   ...       ...  \n",
       "93588    962546588  shhh       194  \n",
       "93982    979999637  shhh       194  \n",
       "94031    981603802  shhh       194  \n",
       "94376     99567121  shhh       194  \n",
       "94398    996627508  shhh       194  \n",
       "\n",
       "[411 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.query(\"sign=='shhh'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
